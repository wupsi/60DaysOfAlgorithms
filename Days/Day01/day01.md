
## Complexity, Memory - Day 1

Сегодня я хочу разобраться в сложности и расходе памяти алгоритмов. Об этом куча информации в интернете, поэтому, разобраться, например с Big O Notation не будет для нас проблемой.

## Оценка сложности алгоритма по времени

Перед использованием какого-либо алгоритма будет правильным знать о времени выполнения и расходе памяти алгоритма. Время выполнения алгоритма в программировании принято называть "сложностью алгоритмов". Точное время алгоритма зависит от разных факторов: от входных данных(массив размеров 100 обработается быстрее, чем массив размеров 10000 или 100000), от процессора, типа данных, языка программирования(в нашем случае С++ считается одним из самых быстрых языков программирования) и множества других параметров. Но из всего этого нас интересует лишь асимптотическая сложность.

#### Пример

Допустим, что у нас есть некий алгоритм, который должен выполниться за $4n^3 + 7n$ операции, чтобы обработать n элементов входных данных. При увеличении `n` на итоговое время работы будет значительно больше влиять возведение `n` в куб, чем умножение его на `4` или же прибавление `7n`. Тогда говорят, что сложность этого алгоритма - O($n^3$).

### Другие примеры

К примеру, давайте найдем сумму элементов массива.
```
#include <iostream>
using namespace std;

int main(){
	
	int n = 5;
	int sum = 0;
	int arr[n] = {4, 2, 3, 5, 1};

	for(int i = 0; i < 5; i++){
		sum = sum + arr[i];
	}
	
	cout << sum;
}
```
`Output: 15`

Здесь, чтобы найти сумму всех элементов массива, нам пришлось пройти по всем $n$ элементам массива(здесь `n = 5` -- размер массива). Тогда, каким бы у нас не был n, наша асимптотика будет `O(n)`.

#### Скорость алгоритма в O(n) называется линейная сложность.

Можем ли мы сделать суммирование более эффективным? В общем случае нет. А если мы знаем, что массив гарантированно начинается с 1, отсортирован и не имеет пропусков? Тогда можно применить формулу $S = \frac{n * (n + 1)}{2}$ - где `n` последний элемент массива.
```
#include  <iostream>
using  namespace  std;

int  main(){

	int n =  5, sum =  0;
	int arr[n] = {1, 2, 3, 4, 5};
	int lastElement = arr[n -  1];
	// наш последний элемент
	
	cout << lastElement * (lastElement +  1) /  2;
}
```
`Output: 15`

Такой алгоритм гораздо эффективнее `O(n)`, здесь работа алгоритма не зависит от входных данных. Здесь мы не пробегались по всем n элементам, а лишь нашли один из элементов массива. Такая сложность обозначается как `O(1)`, или "константное время".

#### Еще один пример на O(1):

Возьмем массив из 10 чисел:

```
int arr[10] = {4, 2, 7, 3, 5, 1, 9, 6, 8, 10};
```
Допустим надо получить 3-й элемент, тогда мы просто указываем на индекс:
```
int arr[10] = {4, 2, 7, 3, 5, 1, 9, 6, 8, 10};
int third = arr[2];
cout << third;
```
`Output: 7`

В нашем случае входных параметров 10(элементов массива, которые мы должны будем вводить вручную), а для получения результата надо выполнить лишь одну операцию - это и есть `O(1)`.

#### O(log n) — логарифмическая сложность

Если мы пройдемся по массиву размером `n = 100`  обычным циклом, у нас получится 100 операции(асимптотика `O(n)`).  Но в случае, когда массив отсортирован, мы можем использовать бинарный поиск. Проверим средний элемент массива, если он больше искомого, то отбросим правую половину массива — там его точно нет. Если же меньше, то наоборот — отбросим левую половину. И так будем продолжать делить пополам, в итоге проверим `log n` элементов:
```
#include  <iostream>
using  namespace  std;  

int  binarySearch(int  arr[], int  l, int  r, int  x){
	if(r >= l){
		int mid = l + (r - l) /  2;
		if(arr[mid] == x) 
			return mid;
		if (arr[mid] > x)
			return  binarySearch(arr, l, mid -  1, x);
		return  binarySearch(arr, mid +  1, r, x);
	}
	return  -1;
}

int  main(){

	int x =  36, n =  15;
	int nums[n] = {1, 2, 3, 4, 6, 8, 10, 15, 22, 25, 27, 30, 36, 45, 47};

	cout <<  "Index of "  << x <<  " in array: "  <<  binarySearch(nums, 0, n -  1, x);
}
```

`Output: Index of 36 in array: 12`

В массиве размером 15 выполнилось 4 операции для нахождения искомого числа. И мы говорим что это логарифмическая сложность `O(logn)`.

### $O(n^2)$ — квадратичная сложность

Такую сложность имеет, например, алгоритм сортировки пузырьком. В сортировке пузырьком нужно последовательно сравнивать значения соседних элементов и менять числа местами, если предыдущее оказывается больше последующего. Получается `O(n)` внутри `O(n)`, что в сумме дает $O(n^2)$. 

## Оценка сложности алгоритма по памяти

Используемая алгоритмом память имеет не меньшую роль в коде, поэтому было бы не лишним узнать о расходах памяти алгоритма. 


```
int findIndexByValue(int arr[], int n, int value){
	int result = -1; 
	for(int i = 0; i < n; i++){
		if(arr[i] == value){
			result = i; 
		}
	}
	return result; 
}
```
В этом примере сложность алгоритма `O(n)`, а сложность памяти `O(1)`, так как мы используем 1 новую переменную.

```
int findAllNumbersGreater(int arr[], int n, int value){
	int cnt = 0;
	int newArr[n];
	for(int i = 0; i < n; i++)
		if(arr[i] > value)
			newArr[cnt++] = arr[i];
	
	return newArr;
}
```
В данном случае мы выделяем место под новый массив и новую переменную. Получается `O(n + 1)`, сокращаем, и получается сложность по памяти `O(n)`.

## Использованные материалы

- [Оценка сложности алгоритмов, или Что такое О(log n)](https://tproger.ru/articles/computational-complexity-explained/)

- [Знай сложности алгоритмов](https://habr.com/ru/post/188010/)
- [Big O](https://habr.com/ru/post/444594/)
- [Сложность алгоритмов по памяти](https://proselyte.net/algorithms/intro/algorithms-complexity/)